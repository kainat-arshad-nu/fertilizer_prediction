# -*- coding: utf-8 -*-
"""Fertilizer_SVM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qVa9VaXhkpKXqLJSxd9_bNoRXwZolD1M
"""

# -*- coding: utf-8 -*-
"""Fertilizer_PredictionML.ipynb
Automatically generated by Colaboratory.
Original file is located at
    https://colab.research.google.com/drive/1fgbyLpjn1c3xDjnz7ocuNRoJUh4CV6Cs
"""

# Commented out IPython magic to ensure Python compatibility.
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import imblearn
from imblearn.over_sampling import SMOTE
from collections import Counter
import matplotlib.patches as mpatches
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.pipeline import make_pipeline
from sklearn.model_selection import train_test_split
from sklearn.neighbors import  KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, plot_confusion_matrix, confusion_matrix


# %matplotlib inline
#from google.colab import drive
#drive.mount("/content/gdrive")

dataset =pd.read_csv('Fertilizer_Prediction.csv')
newsubset = []
dataset.drop(['Soiltype'], axis=1, inplace=True)
dataset.drop(['Croptype'], axis=1, inplace=True)
datalabels = ['Urea', 'DAP', '14-35-14', '28-28', '17-17-17', '20-20', '10-26-26']

for i in datalabels:
    newsubset.append(dataset.loc[dataset['Fertilizername'] == i])

df= pd.concat(newsubset, ignore_index = True)
print(df)

df.columns

X = df[df.columns[:-1]]
y = df[df.columns[-1]]
print(X.shape)
print(y.shape)

upsample = SMOTE()
X, y = upsample.fit_resample(X, y)
print(X.shape)
print(y.shape)

X_train, X_test, y_train, y_test = train_test_split(X.values, y, test_size = 0.2, random_state = 0)
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=0)

print(f"Train Data: {X_train.shape}, {y_train.shape}")
print(f"Test Data: {X_test.shape}, {y_test.shape}")
print(f"Validation Data: {X_val.shape}")

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
# Fit on training set only.
X_train = scaler.fit_transform(X_train)

# Apply transform to both the training set and the test set.
X_test= scaler.transform(X_test)
X_val = scaler.transform(X_val)

'''
from sklearn.decomposition import PCA
pca = PCA(n_components=2)
X_train = pca.fit_transform(X_train)
X_test = pca.transform(X_test)
X_val = pca.transform(X_val)
#print(X_train)
'''

#print(X_test)

#print(X_val)
'''
"""### DECISION TREE """

from sklearn import tree # tree class 
import numpy as np
from sklearn.tree import DecisionTreeClassifier
from sklearn.tree import export_text
import graphviz # excellent python utility for visualizing the trees
clf = tree.DecisionTreeClassifier(criterion = 'entropy',splitter='random')
clf = clf.fit(X_train,y_train)

from sklearn import metrics
from sklearn.metrics import accuracy_score
score = clf.score(X_val, y_val)
print(" accuracy=%.4f%%" %  (score * 100))

# test data
import seaborn as sns
import pandas as pd
from sklearn.metrics import classification_report
predictions = clf.predict(X_test)
# show a final classification report demonstrating the accuracy of the classifier
# for each of the digits
print("EVALUATION ON TESTING DATA")
report = (classification_report(y_test, predictions,output_dict=True)) # made the output of report as dictionary
print (report)
sns.heatmap(pd.DataFrame(report).iloc[:-1, :].T, annot=True)

"""### KNN"""

# import the necessary packages
from __future__ import print_function
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report
from sklearn import datasets
from skimage import exposure
import numpy as np
import sklearn

kVals = range(1, 30, 2)
accuracies = []

# loop over various values of `k` for the k-Nearest Neighbor classifier
for k in range(1, 30, 2):
	# train the k-Nearest Neighbor classifier with the current value of `k`
	model = KNeighborsClassifier(n_neighbors=k)
	model.fit(X_train, y_train)

	# evaluate the model and update the accuracies list
	score = model.score(X_val, y_val)
	print("k=%d, accuracy=%.2f%%" % (k, score * 100))
	accuracies.append(score)

# find the value of k that has the largest accuracy
i = int(np.argmax(accuracies))
print("k=%d achieved highest accuracy of %.2f%% on validation data" % (kVals[i],
	accuracies[i] * 100))

# test data
import seaborn as sns
import pandas as pd
from sklearn.metrics import classification_report
predictions = clf.predict(X_test)
# show a final classification report demonstrating the accuracy of the classifier
# for each of the digits
print("EVALUATION ON TESTING DATA")
report = (classification_report(y_test, predictions,output_dict=True)) # made the output of report as dictionary
print (report)
sns.heatmap(pd.DataFrame(report).iloc[:-1, :].T, annot=True)
'''

"""## **SVM**"""

from sklearn.svm import SVC
import numpy as np
print('Kernal is poly and Loop on Values of C')
Crange=np.arange(0.1,1.05,0.05)
accuracies = []
#print(Crange)
for index in Crange:
	# train the classifier with the current value of `C`
	model = SVC(C=index,kernel='poly')
	model.fit(X_train,y_train)

	# evaluate the model and update the accuracies list
	score = model.score(X_val, y_val)
	print("C=%.2f%%, accuracy=%.4f%%" % (index, score * 100))
	accuracies.append(score)
  

#largest accuracy
maxx = int(np.argmax(accuracies))
print("C=%.2f%% achieved highest accuracy of %.2f%% on validation data" % (Crange[maxx],accuracies[maxx] * 100))
print("Training model with highest accuracy")
model = SVC(C=maxx,kernel='poly')
model.fit(X_train,y_train)
score = model.score(X_val, y_val)
print("Score is ", score)
# test data
import seaborn as sns
import pandas as pd
from sklearn.metrics import classification_report
predictions = clf.predict(X_test)
# show a final classification report demonstrating the accuracy of the classifier
# for each of the digits
print("EVALUATION ON TESTING DATA")
report = (classification_report(y_test, predictions,output_dict=False)) # made the output of report as dictionary
print (report)